{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791992c5-beec-48ef-9796-440674adea4e",
   "metadata": {},
   "source": [
    "1) What is inductive reasoning? Deductive reasoning? Give an example of each, different from the examples given in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01a3086-3b16-4c4d-b662-4a2e66fdb44f",
   "metadata": {},
   "source": [
    "Inductive Reasoning is a way to draw conclusions by going from specific information to general conclusion, like sickness, where you see specific \n",
    "symptoms like a cough, dry throat, or congestion, then you find a general solution like a common cold.\n",
    "\n",
    "Deductive Reasoning is the opposite of inductive, moving from general information to a specific conclusion, usually in a A=B, B=C, so A=C format. For\n",
    "example, Cats are cool, all cool things are cute, therefore all cats are cute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89dd66bd-3be1-47b6-8559-813d8ba75fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cded985-b27b-47ad-8332-8cca04fa9063",
   "metadata": {},
   "source": [
    "2) Preprocess your dataset. (I'm using the Credit Card.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e966b52a-8652-4f7f-9161-9fd8b1e6d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pd.read_csv(\"Credit_card.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0196bd7-2b26-4aca-91ad-a5cb7f1de7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing simple binary answers like gender to 1 and 2\n",
    "def change_dt(x):\n",
    "    xy = {'M':0,'F':1}\n",
    "    cc['GENDER'] = cc['GENDER'].map(xy)\n",
    "\n",
    "    co = {'Y':0,'N':1}\n",
    "    cc['Car_Owner'] = cc['Car_Owner'].map(co)\n",
    "\n",
    "    po = {'Y':0,'N':1}\n",
    "    cc['Propert_Owner'] = cc['Propert_Owner'].map(po)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "336f44fb-01d3-47f6-b801-11d4fab0e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_dt(\"Credit_card.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b3b0c72-5716-49de-898b-7faec583e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = cc.drop('Type_Occupation', axis=1)\n",
    "cc = cc.drop('EDUCATION', axis=1)\n",
    "cc = cc.drop('Marital_status', axis=1)\n",
    "cc = cc.drop('Housing_type', axis=1)\n",
    "cc = cc.drop('Type_Income', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed78cb7-41f1-4a14-a9fa-de2cb2b5e93c",
   "metadata": {},
   "source": [
    "3) Create a decision tree model tuned to the best of your abilities. Explain how you tuned it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9407d59a-1a21-4d83-9747-55d6e9f40f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt(x):\n",
    "    X = cc.drop('Car_Owner',axis=1)\n",
    "    y = cc['Car_Owner']\n",
    "\n",
    "    #split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=42)\n",
    "    \n",
    "    model = tree.DecisionTreeClassifier(max_depth=7, random_state=42, min_impurity_decrease=0.01)\n",
    "    \n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "\n",
    "    tree.plot_tree(model, feature_names=list(X.columns),\n",
    "               filled=True, fontsize=6, rounded=True)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef32d96-26f6-4325-8401-5df0025ae501",
   "metadata": {},
   "source": [
    "4) Create a random forest model tuned to the best of your abilities. Explain how you tuned it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b9fced4-1fe5-4137-af9b-d45a1e4852cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(x):\n",
    "    global X_test, X_train\n",
    "    sc = StandardScaler()\n",
    "    X_test = sc.fit_transform(X_test)\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf = rf.fit(X_train, y_train)\n",
    "    rf.score(X_test, y_test)\n",
    "\n",
    "    print(rf.feature_importances_, X.columns)\n",
    "\n",
    "    rf_tree = rf.estimators_[4]\n",
    "    tree.plot_tree(rf_tree)\n",
    "    plt.savefig(\"rf_tree.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74140c-d765-4100-be1e-77ba2a0229b7",
   "metadata": {},
   "source": [
    "5) Create an xgboost model tuned to the best of your abilities. Explain how you tuned it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6dce44d5-b3b0-439f-9aa4-5bff6bd68e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgmodel1(x):\n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb.predict(X_test)\n",
    "\n",
    "    ConfusionMatrixDisplay.from_estimator(xgb, X_test, y_test)\n",
    "\n",
    "    print(type(y_test))\n",
    "    print(type(y_pred))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(fpr, tpr)\n",
    "    auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d713449-c46d-4773-a0ff-a52416550ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgmodel2(x):\n",
    "    global recall, precision\n",
    "    plt.plot(recall, precision, marker = \".\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    pr_auc\n",
    "\n",
    "    plt.plot(recall, precision, marker = \".\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3121f56-457b-454b-9d09-b224d55b9221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.637 (0.120)\n"
     ]
    }
   ],
   "source": [
    "#Singular Value Decomposition\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "X, y = make_classification(n_samples=100, n_features=20, n_informative=10, n_redundant=10, random_state=42)\n",
    "\n",
    "# define the pipeline\n",
    "\n",
    "steps = [('Credit_Card.csv', TruncatedSVD(n_components=5)), ('m', LogisticRegression())]\n",
    "model = Pipeline(steps=steps)\n",
    "\n",
    "# evaluate model\n",
    "\n",
    "cc = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report performance\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9524b4-6963-4b85-9b26-9653321a641c",
   "metadata": {},
   "source": [
    "As I change and tweak the code it gets worse in some aspects and gets less reliable (changing the random state and n_samples), so the more I change the \n",
    "worse it gets for the most parts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7621e7-558c-49aa-acf2-9522ffbaa94b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
